{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0d034eac455ef6a0de03e633f02c98f91f1b386010bcd71958f296e7d2ac4641b",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from konlpy.tag import Komoran, Kkma, Okt\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from math import log\n",
    "from operator import itemgetter\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('D:/LikeLion/Code/Project2/Data/spell_check_label.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('D:/LikeLion/Code/Project2/Data/kor_stop.txt', 'r', encoding='utf-8') as f:\n",
    "    list_file = f.readlines()\n",
    "stopwords = [line.rstrip('\\n') for line in list_file] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_name = list(dataset.groupby('hotelName').count().index)\n",
    "groups = dataset.groupby(dataset.hotelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, name in enumerate(hotel_name):\n",
    "    globals()['df_{}'.format(i)] = groups.get_group(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0_neg = df_0[df_0['label']==0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0_neg['fixed'] = df_0_neg['fixed'].apply(lambda x: re.sub(r\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\",x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_count = len(df_0_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "komoran = Komoran(userdic='D:/LikeLion/Code/Project2/Data/userdic.txt')\n",
    "kkma = Kkma()\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    # josa = ['JKS', 'JKC', 'JKG', 'JKO', 'JKB', 'JKV', 'JKQ', 'JX', 'JC', 'EP', 'EF', 'EC', 'ETN', 'ETM', 'XPN', 'XSN', 'XSV', 'XSA', 'XR']\n",
    "    pos_tag = ['NNG', 'NNP', 'NNB', 'NP', 'NR', 'VA', 'MM', 'MAG', 'XR']\n",
    "    tokens_pos = komoran.pos(text)\n",
    "    tokens_word = [] \n",
    "    for tag in tokens_pos:\n",
    "        if tag[1] in pos_tag:\n",
    "            if tag[0] not in stopwords:\n",
    "                tokens_word.append(tag[0])\n",
    "    return re.sub('\\.','',' '.join(tokens_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0_neg['fixed'] = df_0_neg['fixed'].apply(lambda x: tokenizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = df_0_neg['fixed'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tokenize(sent):\n",
    "#     words = komoran.pos(sent, join=True)\n",
    "#     words = [w for w in words if ('/NN' in w or '/XR' in w or '/VA' in w or '/VV' in w or '/VX' in w or '/VC' in w or '/MM' in w or '/MA' in w or '/IC' in w\n",
    "#                                   or '/E' in w or '/XP' in w or '/XS' in w or '/XR' in w or '/SF' in w or '/SP' in w or '/SS' in w or '/SE' in w or '/SO' in w\n",
    "#                                   or '/SL' in w or '/SW' in w or '/NF' in w or '/NV' in w or '/SN' in w )]\n",
    "#     return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_term_frequency(document, word_dict=None):\n",
    "    if word_dict is None:\n",
    "        word_dict = {}\n",
    "    words = document.split()\n",
    "\n",
    "    for w in words:\n",
    "        word_dict[w] = 1 + (0 if word_dict.get(w) is None else word_dict[w])\n",
    "\n",
    "    return pd.Series(word_dict, dtype='float64').sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_frequency(documents):\n",
    "    dicts = []\n",
    "    vocab = set([])\n",
    "    df = {}\n",
    "\n",
    "    for d in documents:\n",
    "        tf = get_term_frequency(d)\n",
    "        dicts += [tf]\n",
    "        vocab = vocab | set(tf.keys())\n",
    "\n",
    "    for v in list(vocab):\n",
    "        df[v] = 0\n",
    "        for dict_d in dicts:\n",
    "            if dict_d.get(v) is not None:\n",
    "                df[v] += 1\n",
    "    \n",
    "    return pd.Series(df, name='df', dtype='float64').sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf(docs):\n",
    "    vocab = {}\n",
    "    tfs = []\n",
    "    for d in docs:\n",
    "        vocab = get_term_frequency(d, vocab)\n",
    "        tfs += [get_term_frequency(d)]\n",
    "\n",
    "    stats = []\n",
    "\n",
    "    for word, freq in vocab.items():\n",
    "        tf_v = []\n",
    "        for idx in range(len(docs)):\n",
    "            if tfs[idx].get(word) is not None:\n",
    "                tf_v += [tfs[idx][word]]\n",
    "            \n",
    "            else:\n",
    "                tf_v += [0]\n",
    "\n",
    "        stats.append((word, freq, *tf_v))\n",
    "\n",
    "    column_name = ['word','totalFrequency']\n",
    "\n",
    "    for i in range(1, len(docs)+1):\n",
    "        column_name.append('document'+str(i))\n",
    "\n",
    "    return pd.DataFrame(stats, columns=column_name).sort_values('totalFrequency', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_tfidf(docs):\n",
    "#     vocab = {}\n",
    "#     tfs = []\n",
    "#     for d in docs:\n",
    "#         vocab = get_term_frequency(d, vocab)\n",
    "#         tfs += [get_term_frequency(d)]\n",
    "    \n",
    "#     df = get_document_frequency(docs)\n",
    "\n",
    "#     stats = []\n",
    "\n",
    "#     for word, freq in vocab.items():\n",
    "#         tfidfs = []\n",
    "#         for idx in range(len(docs)):\n",
    "#             if tfs[idx].get(word) is not None:\n",
    "#                 tfidfs += [tfs[idx][word] * np.log(len(docs) / df[word])]\n",
    "            \n",
    "#             else:\n",
    "#                 tfidfs += [0]\n",
    "\n",
    "#         stats.append((word, freq, *tfidfs, max(tfidfs)))\n",
    "    \n",
    "#     column_name = ['word','totalFrequency']\n",
    "\n",
    "#     for i in range(1, len(docs)+1):\n",
    "#         column_name.append('document'+str(i))\n",
    "    \n",
    "#     column_name.append('max')\n",
    "\n",
    "#     return pd.DataFrame(stats, columns=column_name).sort_values('max', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_matrix = get_tf(documents)\n",
    "df_matrix = get_document_frequency(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "먼지    29.0\n",
       "청소    28.0\n",
       "방음    26.0\n",
       "침대    25.0\n",
       "객실    22.0\n",
       "      ... \n",
       "물이     1.0\n",
       "착용     1.0\n",
       "사진     1.0\n",
       "사인     1.0\n",
       "미술     1.0\n",
       "Name: df, Length: 770, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "df_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    word  totalFrequency  document1  document2  document3  document4  \\\n",
       "0     청소            30.0          0        0.0        0.0        0.0   \n",
       "1     먼지            30.0          0        0.0        1.0        0.0   \n",
       "2     침대            29.0          0        0.0        0.0        0.0   \n",
       "3     방음            27.0          0        0.0        0.0        0.0   \n",
       "4     객실            22.0          0        0.0        0.0        0.0   \n",
       "..   ...             ...        ...        ...        ...        ...   \n",
       "468  공사장             1.0          0        0.0        0.0        0.0   \n",
       "467   정비             1.0          0        0.0        0.0        0.0   \n",
       "466    통             1.0          0        0.0        0.0        0.0   \n",
       "465  상당히             1.0          0        0.0        0.0        0.0   \n",
       "769   시기             1.0          0        0.0        0.0        0.0   \n",
       "\n",
       "     document5  document6  document7  document8  ...  document415  \\\n",
       "0          0.0          0        0.0        0.0  ...          0.0   \n",
       "1          0.0          0        0.0        0.0  ...          0.0   \n",
       "2          0.0          0        0.0        0.0  ...          0.0   \n",
       "3          0.0          0        0.0        0.0  ...          0.0   \n",
       "4          0.0          0        0.0        0.0  ...          0.0   \n",
       "..         ...        ...        ...        ...  ...          ...   \n",
       "468        0.0          0        0.0        0.0  ...          0.0   \n",
       "467        0.0          0        0.0        0.0  ...          0.0   \n",
       "466        0.0          0        0.0        0.0  ...          0.0   \n",
       "465        0.0          0        0.0        0.0  ...          0.0   \n",
       "769        0.0          0        0.0        0.0  ...          0.0   \n",
       "\n",
       "     document416  document417  document418  document419  document420  \\\n",
       "0            0.0          0.0          0.0          0.0          0.0   \n",
       "1            1.0          0.0          0.0          0.0          0.0   \n",
       "2            1.0          0.0          0.0          0.0          0.0   \n",
       "3            0.0          0.0          0.0          0.0          0.0   \n",
       "4            0.0          0.0          0.0          0.0          0.0   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "468          0.0          0.0          0.0          0.0          0.0   \n",
       "467          0.0          0.0          0.0          0.0          0.0   \n",
       "466          0.0          0.0          0.0          0.0          0.0   \n",
       "465          0.0          0.0          0.0          0.0          0.0   \n",
       "769          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "     document421  document422  document423  document424  \n",
       "0            0.0          0.0          0.0          0.0  \n",
       "1            0.0          0.0          0.0          0.0  \n",
       "2            0.0          0.0          0.0          0.0  \n",
       "3            0.0          0.0          0.0          0.0  \n",
       "4            0.0          0.0          0.0          0.0  \n",
       "..           ...          ...          ...          ...  \n",
       "468          0.0          0.0          0.0          0.0  \n",
       "467          0.0          0.0          0.0          0.0  \n",
       "466          0.0          0.0          0.0          0.0  \n",
       "465          0.0          0.0          0.0          0.0  \n",
       "769          0.0          0.0          0.0          0.0  \n",
       "\n",
       "[770 rows x 426 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n      <th>totalFrequency</th>\n      <th>document1</th>\n      <th>document2</th>\n      <th>document3</th>\n      <th>document4</th>\n      <th>document5</th>\n      <th>document6</th>\n      <th>document7</th>\n      <th>document8</th>\n      <th>...</th>\n      <th>document415</th>\n      <th>document416</th>\n      <th>document417</th>\n      <th>document418</th>\n      <th>document419</th>\n      <th>document420</th>\n      <th>document421</th>\n      <th>document422</th>\n      <th>document423</th>\n      <th>document424</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>청소</td>\n      <td>30.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>먼지</td>\n      <td>30.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>침대</td>\n      <td>29.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>방음</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>객실</td>\n      <td>22.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>468</th>\n      <td>공사장</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>467</th>\n      <td>정비</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>466</th>\n      <td>통</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>465</th>\n      <td>상당히</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>769</th>\n      <td>시기</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>770 rows × 426 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "tf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ntf(matrix):\n",
    "    max_btf = max(matrix['totalFrequency'])\n",
    "    total_btf = sum(matrix['totalFrequency'])\n",
    "\n",
    "    col_names = list(matrix.columns)[2:]\n",
    "\n",
    "    matrix['ntf1'] = matrix['totalFrequency'].apply(lambda x: x/max_btf)\n",
    "\n",
    "    matrix_ntf2 = matrix[col_names].copy()\n",
    "\n",
    "    matrix_ntf2 = matrix_ntf2.apply(lambda x: x/total_btf , axis=1)\n",
    "    \n",
    "    matrix_ntf2['ntf2'] = matrix_ntf2.apply(sum, axis=1)\n",
    "\n",
    "    matrix['ntf2'] = matrix_ntf2['ntf2']\n",
    "\n",
    "    return matrix[['word','totalFrequency','ntf1','ntf2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntf_matrix = get_ntf(tf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ntf_idf(ntf, df):\n",
    "\n",
    "    ntf = ntf.set_index('word')\n",
    "    ntf_idf = pd.concat([ntf, df], axis=1)\n",
    "\n",
    "\n",
    "    def get_btfidf(scores):\n",
    "        global document_count\n",
    "        return (np.log(scores['totalFrequency']) + 1.0) * np.log(document_count/scores['df'])\n",
    "\n",
    "    def get_ntf1idf(scores):\n",
    "        global document_count\n",
    "        return (np.log(scores['ntf1']) + 1.0) * np.log(document_count/scores['df'])\n",
    "\n",
    "    def get_ntf2idf(scores):\n",
    "        global document_count\n",
    "        return (np.log(scores['ntf2']) + 1.0) * np.log(document_count/scores['df'])\n",
    "\n",
    "    \n",
    "    ntf_idf['btf_idf'] = ntf_idf.apply(get_btfidf, axis=1)\n",
    "    ntf_idf['ntf1_idf'] = ntf_idf.apply(get_ntf1idf, axis=1)\n",
    "    ntf_idf['ntf2_idf'] = ntf_idf.apply(get_ntf2idf, axis=1)\n",
    "\n",
    "    btf_rank = ntf_idf['btf_idf'].sort_values(ascending=False)\n",
    "    ntf1_rank = ntf_idf['ntf1_idf'].sort_values(ascending=False)\n",
    "    ntf2_rank = ntf_idf['ntf2_idf'].sort_values(ascending=False)\n",
    "\n",
    "    return btf_rank, ntf1_rank, ntf2_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "btf_rank , ntf1_rank, ntf2_rank = get_ntf_idf(ntf_matrix, df_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# btf_rank.to_csv('../../Data/btf.csv', encoding='utf-8-sig')\n",
    "# ntf1_rank.to_csv('../../Data/ntf1.csv',encoding='utf-8-sig')\n",
    "# ntf2_rank.to_csv('../../Data/ntf2.csv', encoding='utf-8-sig')"
   ]
  }
 ]
}
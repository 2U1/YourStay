{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python373jvsc74a57bd0e48d23369a553edc96f1373b6255b5687d82d68cd08867622b2500e338930542",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from konlpy.tag import Komoran, Kkma, Okt\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from math import log\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('D:/LikeLion/Code/Project2/Data/spell_check_label.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('D:/LikeLion/Code/Project2/Data/kor_stop.txt', 'r', encoding='utf-8') as f:\n",
    "    list_file = f.readlines()\n",
    "stopwords = [line.rstrip('\\n') for line in list_file] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_name = list(dataset.groupby('hotelName').count().index)\n",
    "groups = dataset.groupby(dataset.hotelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, name in enumerate(hotel_name):\n",
    "    globals()['df_{}'.format(i)] = groups.get_group(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0_neg = df_0[df_0['label']==0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0_neg['fixed'] = df_0_neg['fixed'].apply(lambda x: re.sub(r\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\",x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_count = len(df_0_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "komoran = Komoran(userdic='D:/LikeLion/Code/Project2/Data/userdic.txt')\n",
    "kkma = Kkma()\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    tokens_ko = komoran.morphs(text)\n",
    "    to_return = []\n",
    "    for words in tokens_ko:\n",
    "        if words not in stopwords:\n",
    "            to_return.append(words)\n",
    "    return re.sub('\\.','',' '.join(to_return))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0_neg['fixed'] = df_0_neg['fixed'].apply(lambda x: tokenizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = df_0_neg['fixed'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_term_frequency(document, word_dict=None):\n",
    "    if word_dict is None:\n",
    "        word_dict = {}\n",
    "    words = document.split()\n",
    "\n",
    "    for w in words:\n",
    "        word_dict[w] = 1 + (0 if word_dict.get(w) is None else word_dict[w])\n",
    "\n",
    "    return pd.Series(word_dict, dtype='float64').sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_frequency(documents):\n",
    "    dicts = []\n",
    "    vocab = set([])\n",
    "    df = {}\n",
    "\n",
    "    for d in documents:\n",
    "        tf = get_term_frequency(d)\n",
    "        dicts += [tf]\n",
    "        vocab = vocab | set(tf.keys())\n",
    "\n",
    "    for v in list(vocab):\n",
    "        df[v] = 0\n",
    "        for dict_d in dicts:\n",
    "            if dict_d.get(v) is not None:\n",
    "                df[v] += 1\n",
    "    \n",
    "    return pd.Series(df, name='df', dtype='float64').sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf(docs):\n",
    "    vocab = {}\n",
    "    tfs = []\n",
    "    for d in docs:\n",
    "        vocab = get_term_frequency(d, vocab)\n",
    "        tfs += [get_term_frequency(d)]\n",
    "\n",
    "    stats = []\n",
    "\n",
    "    for word, freq in vocab.items():\n",
    "        tf_v = []\n",
    "        for idx in range(len(docs)):\n",
    "            if tfs[idx].get(word) is not None:\n",
    "                tf_v += [tfs[idx][word]]\n",
    "            \n",
    "            else:\n",
    "                tf_v += [0]\n",
    "\n",
    "        stats.append((word, freq, *tf_v))\n",
    "\n",
    "    column_name = ['word','totalFrequency']\n",
    "\n",
    "    for i in range(1, len(docs)+1):\n",
    "        column_name.append('document'+str(i))\n",
    "\n",
    "    return pd.DataFrame(stats, columns=column_name).sort_values('totalFrequency', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_tfidf(docs):\n",
    "#     vocab = {}\n",
    "#     tfs = []\n",
    "#     for d in docs:\n",
    "#         vocab = get_term_frequency(d, vocab)\n",
    "#         tfs += [get_term_frequency(d)]\n",
    "    \n",
    "#     df = get_document_frequency(docs)\n",
    "\n",
    "#     stats = []\n",
    "\n",
    "#     for word, freq in vocab.items():\n",
    "#         tfidfs = []\n",
    "#         for idx in range(len(docs)):\n",
    "#             if tfs[idx].get(word) is not None:\n",
    "#                 tfidfs += [tfs[idx][word] * np.log(len(docs) / df[word])]\n",
    "            \n",
    "#             else:\n",
    "#                 tfidfs += [0]\n",
    "\n",
    "#         stats.append((word, freq, *tfidfs, max(tfidfs)))\n",
    "    \n",
    "#     column_name = ['word','totalFrequency']\n",
    "\n",
    "#     for i in range(1, len(docs)+1):\n",
    "#         column_name.append('document'+str(i))\n",
    "    \n",
    "#     column_name.append('max')\n",
    "\n",
    "#     return pd.DataFrame(stats, columns=column_name).sort_values('max', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_matrix = get_tf(documents)\n",
    "df_matrix = get_document_frequency(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "어요      98.0\n",
       "ㄴ       86.0\n",
       "있       74.0\n",
       "안       67.0\n",
       "좋       64.0\n",
       "        ... \n",
       "와도       1.0\n",
       "전기       1.0\n",
       "개미       1.0\n",
       "끈        1.0\n",
       "초코파이     1.0\n",
       "Name: df, Length: 1074, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "df_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      word  totalFrequency  document1  document2  document3  document4  \\\n",
       "0       어요            98.0          0        1.0        0.0        0.0   \n",
       "1        ㄴ            97.0          0        0.0        0.0        1.0   \n",
       "2        있            91.0          0        0.0        2.0        0.0   \n",
       "3        안            72.0          0        0.0        0.0        0.0   \n",
       "4        좋            65.0          0        0.0        1.0        1.0   \n",
       "...    ...             ...        ...        ...        ...        ...   \n",
       "680     빠지             1.0          0        0.0        0.0        0.0   \n",
       "681    서약서             1.0          0        0.0        0.0        0.0   \n",
       "682     찬물             1.0          0        0.0        0.0        0.0   \n",
       "683   트윈침대             1.0          0        0.0        0.0        0.0   \n",
       "1073    붙이             1.0          0        0.0        0.0        0.0   \n",
       "\n",
       "      document5  document6  document7  document8  ...  document415  \\\n",
       "0           1.0        0.0        0.0        1.0  ...          0.0   \n",
       "1           0.0        0.0        0.0        0.0  ...          0.0   \n",
       "2           0.0        0.0        0.0        0.0  ...          1.0   \n",
       "3           0.0        0.0        0.0        1.0  ...          1.0   \n",
       "4           0.0        0.0        0.0        0.0  ...          0.0   \n",
       "...         ...        ...        ...        ...  ...          ...   \n",
       "680         0.0        0.0        0.0        1.0  ...          0.0   \n",
       "681         0.0        0.0        0.0        0.0  ...          0.0   \n",
       "682         0.0        0.0        0.0        0.0  ...          0.0   \n",
       "683         0.0        0.0        0.0        0.0  ...          0.0   \n",
       "1073        0.0        0.0        0.0        0.0  ...          0.0   \n",
       "\n",
       "      document416  document417  document418  document419  document420  \\\n",
       "0             1.0          0.0          0.0          0.0          0.0   \n",
       "1             0.0          0.0          2.0          0.0          0.0   \n",
       "2             0.0          0.0          0.0          1.0          0.0   \n",
       "3             0.0          0.0          0.0          0.0          0.0   \n",
       "4             1.0          1.0          0.0          0.0          0.0   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "680           0.0          0.0          0.0          0.0          0.0   \n",
       "681           0.0          0.0          0.0          0.0          0.0   \n",
       "682           0.0          0.0          0.0          0.0          0.0   \n",
       "683           0.0          0.0          0.0          0.0          0.0   \n",
       "1073          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "      document421  document422  document423  document424  \n",
       "0             0.0          1.0          0.0          0.0  \n",
       "1             0.0          1.0          1.0          0.0  \n",
       "2             0.0          0.0          0.0          0.0  \n",
       "3             0.0          0.0          0.0          0.0  \n",
       "4             0.0          1.0          0.0          1.0  \n",
       "...           ...          ...          ...          ...  \n",
       "680           0.0          0.0          0.0          0.0  \n",
       "681           0.0          0.0          0.0          0.0  \n",
       "682           0.0          0.0          1.0          0.0  \n",
       "683           0.0          0.0          0.0          1.0  \n",
       "1073          0.0          0.0          0.0          1.0  \n",
       "\n",
       "[1074 rows x 426 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n      <th>totalFrequency</th>\n      <th>document1</th>\n      <th>document2</th>\n      <th>document3</th>\n      <th>document4</th>\n      <th>document5</th>\n      <th>document6</th>\n      <th>document7</th>\n      <th>document8</th>\n      <th>...</th>\n      <th>document415</th>\n      <th>document416</th>\n      <th>document417</th>\n      <th>document418</th>\n      <th>document419</th>\n      <th>document420</th>\n      <th>document421</th>\n      <th>document422</th>\n      <th>document423</th>\n      <th>document424</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>어요</td>\n      <td>98.0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ㄴ</td>\n      <td>97.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>있</td>\n      <td>91.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>안</td>\n      <td>72.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>좋</td>\n      <td>65.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>680</th>\n      <td>빠지</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>681</th>\n      <td>서약서</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>682</th>\n      <td>찬물</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>683</th>\n      <td>트윈침대</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1073</th>\n      <td>붙이</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1074 rows × 426 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "tf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ntf(matrix):\n",
    "    max_btf = max(matrix['totalFrequency'])\n",
    "    total_btf = sum(matrix['totalFrequency'])\n",
    "\n",
    "    col_names = list(matrix.columns)[2:]\n",
    "\n",
    "    matrix['ntf1'] = matrix['totalFrequency'].apply(lambda x: x/max_btf)\n",
    "\n",
    "    matrix_ntf2 = matrix[col_names].copy()\n",
    "\n",
    "    matrix_ntf2 = matrix_ntf2.apply(lambda x: x/total_btf , axis=1)\n",
    "    \n",
    "    matrix_ntf2['ntf2'] = matrix_ntf2.apply(sum, axis=1)\n",
    "\n",
    "    matrix['ntf2'] = matrix_ntf2['ntf2']\n",
    "\n",
    "    return matrix[['word','totalFrequency','ntf1','ntf2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntf_matrix = get_ntf(tf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ntf_idf(ntf, df):\n",
    "\n",
    "    ntf = ntf.set_index('word')\n",
    "    ntf_idf = pd.concat([ntf, df], axis=1)\n",
    "\n",
    "\n",
    "    def get_btfidf(scores):\n",
    "        global document_count\n",
    "        return (np.log(scores['totalFrequency']) + 1.0) * np.log(document_count/scores['df'])\n",
    "\n",
    "    def get_ntf1idf(scores):\n",
    "        global document_count\n",
    "        return (np.log(scores['ntf1']) + 1.0) * np.log(document_count/scores['df'])\n",
    "\n",
    "    def get_ntf2idf(scores):\n",
    "        global document_count\n",
    "        return (np.log(scores['ntf2']) + 1.0) * np.log(document_count/scores['df'])\n",
    "\n",
    "    \n",
    "    ntf_idf['btf_idf'] = ntf_idf.apply(get_btfidf, axis=1)\n",
    "    ntf_idf['ntf1_idf'] = ntf_idf.apply(get_ntf1idf, axis=1)\n",
    "    ntf_idf['ntf2_idf'] = ntf_idf.apply(get_ntf2idf, axis=1)\n",
    "\n",
    "    btf_rank = ntf_idf['btf_idf'].sort_values(ascending=False)\n",
    "    ntf1_rank = ntf_idf['ntf1_idf'].sort_values(ascending=False)\n",
    "    ntf2_rank = ntf_idf['ntf2_idf'].sort_values(ascending=False)\n",
    "\n",
    "    return btf_rank, ntf1_rank, ntf2_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "btf_rank , ntf1_rank, ntf2_rank = get_ntf_idf(ntf_matrix, df_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "btf_rank.to_csv('../../Data/btf.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntf1_rank.to_csv('../../Data/ntf1.csv',encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntf2_rank.to_csv('../../Data/ntf2.csv', encoding='utf-8-sig')"
   ]
  }
 ]
}